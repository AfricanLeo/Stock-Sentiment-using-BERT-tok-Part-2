{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier Using BERT-tokenizer",
      "provenance": [],
      "collapsed_sections": [
        "6eh7sIquja5t",
        "B-4oGSu5jxUi"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca6rYUxNi_MO"
      },
      "source": [
        "# Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76HfPILdC5lD"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdje5lQStUIq"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1h4YVFfDd1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759e2b29-bdf9-4a23-c20e-02e6e24f4ff5"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 141 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=adcc57143483ec2dfe3fff6a95c77ea8b833a01e9ec1607284a0f1362e772d42\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=a8bf43cd90d1026f2e69ed051dfbe3b54b5438d47b6f7dbc49580b5f41156e6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=368b66c8e635bcf3cc4c7b9f28dda3387edf4a595c7d07134376e65b35aa0dd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMqTwu9jENrO"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw5bdSITgkGA",
        "outputId": "94633a0e-80d4-4eb5-9dcc-2db461b36e1b"
      },
      "source": [
        "print(tf. __version__) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_xu0I3jFP9"
      },
      "source": [
        "# Stage 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v60JTFKojIq5"
      },
      "source": [
        "## Loading files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTtO7NkPjKUd"
      },
      "source": [
        "In this section the dataset is loaded into a pandas dataframe.\n",
        "\n",
        "The **[Stock Market Sentiment Dataset](https://www.kaggle.com/yash612/stockmarket-sentiment-dataset)** is kindly provided on the Kaggle website by [Yash Chaudhary](https://www.kaggle.com/yash612). The dataset contains approximately 6,000 tweets regarding stocks, trading and economic forecasts from twitter. Each tweet was classified as having a **positive(1)** or **negative(0)** sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRCxQui8Gqi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164f3934-bd9d-4208-8fce-e3922561dfb7"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6iT5nxDHLRz"
      },
      "source": [
        "#DATA - Stock Sentiment Analysis from Kaggle\n",
        "data = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/NLP/StockSentiment/stock_sentiment.csv\",\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Cp-2AmxIBvuT",
        "outputId": "a6f2e958-7713-410b-c6d0-5cf21f325449"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MNTA Over 12.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OI  Over 21.37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Sentiment\n",
              "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
              "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
              "2  user I'd be afraid to short AMZN - they are lo...          1\n",
              "3                                  MNTA Over 12.00            1\n",
              "4                                   OI  Over 21.37            1"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Quzx5tnjUtl"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8hlexmRjXIS"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEVUIFefEgFz"
      },
      "source": [
        "In order to understand the tweets, it needs to be cleaned, performing the following actions:\n",
        "\n",
        "\n",
        "*   decoding the tweets from XML\n",
        "*   removing mentions (starting with @-sign)\n",
        "*   removing URL links\n",
        "*   removing special characters\n",
        "*   removing additional white spaces due to above functions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBSUDL-UP-W_"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    #decode tweets from XML\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    # Removing the @\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    # Removing the URL links\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    # Keeping only letters\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    # Removing additional whitespaces\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86s6DY1EmNw"
      },
      "source": [
        "Use the function defined to clean the tweets in the dataset.  This will be the independent variable for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jiMaQsLWiTS"
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.Text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC3HdTG5v01N",
        "outputId": "d55b3e30-2b40-4490-b316-2f2b02aca4d0"
      },
      "source": [
        "type(data_clean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkXS21gAUBsK"
      },
      "source": [
        "Create the data labels that classify the tweets as positive / negative.  These are the  targets / dependent variables to feed into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaqLE0fdWtni"
      },
      "source": [
        "data_labels = data.Sentiment.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eh7sIquja5t"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K59PriX4jgBV"
      },
      "source": [
        "Here we use the BERT tokeniser to generate tokens and token id's for each tweet.  We start by creating an instance of the class **FullTokenizer**.\n",
        "\n",
        "Next we create a BERT layer to give us access to the information we need for the tokenizer.\n",
        "\n",
        "Then we create the tokeniser from the class **FullTokenizer**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wry-st-HMN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f38f3c-11d2-429c-aebc-0714cfd2cdd0"
      },
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "#call and create a BERT layer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)   #we don't want to fine tune right now\n",
        "\n",
        "#Now get the information from the tokeniser           \n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()  #access the vocab file\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()       #lower case the text\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)                   #create tokeniser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.embedding.embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.embedding.embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.embedding.embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.embedding.embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'm' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.embedding.embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.embedding.embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.bigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.trigram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.fourgram.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.dense_1.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.kernel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).Dcnn.optimizer's state 'v' for (root).Dcnn.last_dense.bias\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kudCaN-lbMWF"
      },
      "source": [
        "A quick example to see how the tokeniser works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhxfH3UgbyJb",
        "outputId": "8f4bb141-6a25-4a15-e47f-9e9b3abea871"
      },
      "source": [
        "#some examples\n",
        "tokenizer.tokenize('She has a very pleasant demeanor.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she', 'has', 'a', 'very', 'pleasant', 'demeanor', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bel-Zkdbx4m",
        "outputId": "176b12a8-9ae3-44aa-c6d5-ebce02a3a687"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize('She has a very pleasant demeanor.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2016, 2038, 1037, 2200, 8242, 21745, 1012]"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MiYa09Na9c9"
      },
      "source": [
        "Create a function that returns the token ids in a vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LggMv7k7Z3Ij"
      },
      "source": [
        "def encode_sentence(sent):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGfTo5uIa2is"
      },
      "source": [
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyVx18vU_piJ",
        "outputId": "97dee53e-fab5-40aa-ae60-3d39448b4cf3"
      },
      "source": [
        "type(data_inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Dbdihy_w1u",
        "outputId": "f8b2944c-760e-4305-f485-9f7e2a304a80"
      },
      "source": [
        "data_inputs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22652,\n",
              " 2015,\n",
              " 2006,\n",
              " 2026,\n",
              " 3422,\n",
              " 9863,\n",
              " 8418,\n",
              " 3207,\n",
              " 14841,\n",
              " 2102,\n",
              " 2061,\n",
              " 4160,\n",
              " 1052,\n",
              " 8950,\n",
              " 18133,\n",
              " 2860,\n",
              " 17531,\n",
              " 2480,\n",
              " 19128,\n",
              " 3119,\n",
              " 4118,\n",
              " 2030,\n",
              " 4118,\n",
              " 2156,\n",
              " 3653,\n",
              " 2615,\n",
              " 8466]"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-4oGSu5jxUi"
      },
      "source": [
        "### Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLg0Z7QOj_YZ"
      },
      "source": [
        "Next up we need to create batches of tweets that are padded to have the same lenght.  \n",
        "\n",
        "To minimise the padding tokens, we will not padd all tweets to the same lenght.  Rather we will order tweets by lenght, then create batches and padd each batch to be as wide as the longest tweet in the batch.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS_f6gWsLfLM"
      },
      "source": [
        "data_with_len = [[sent, data_labels[i], len(sent)]\n",
        "                 for i, sent in enumerate(data_inputs)]\n",
        "\n",
        "random.shuffle(data_with_len)                               #shuffle data\n",
        "data_with_len.sort(key=lambda x: x[2])                      #sort according to length\n",
        "sorted_all = [(sent_lab[0], sent_lab[1])\n",
        "              for sent_lab in data_with_len if sent_lab[2] > 3] #keep only tweets "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaOPvqmkggPN"
      },
      "source": [
        "Create a dataset using a generator (because the tweets are not all the same length)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0uJJg8lSQR"
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF74g5hpYzaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcd8a9d-10b6-4620-9d80-c900debbc4cb"
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([5887, 2705, 2844, 2707], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHAhlfTlrcj"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()), drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wisMYbltOVWU",
        "outputId": "8f66e46b-12d2-41ef-d410-2f75297df58c"
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 4), dtype=int32, numpy=\n",
              " array([[ 5887,  2705,  2844,  2707],\n",
              "        [ 9779,  2361,  2733,  2490],\n",
              "        [ 1999, 16216,  6767,  1012],\n",
              "        [ 1050,  4292,  2039, 17950],\n",
              "        [ 9574,  2825, 25129,  2377],\n",
              "        [ 4654,  2232,  2058,  1012],\n",
              "        [10705,  2072,  2058,  1012],\n",
              "        [ 2915,  2012,  2072,  1012],\n",
              "        [10210,  2243,  3048,  2153],\n",
              "        [27937,  2023,  2003,  2009],\n",
              "        [18629,  2559,  3492,  9200],\n",
              "        [20704,  2100,  2058,  1012],\n",
              "        [ 3729,  2595,  2146,  1012],\n",
              "        [ 1049,  1996, 25129,  7172],\n",
              "        [ 9779, 10882,  5910,  2814],\n",
              "        [14925,  3835,  2275,  2039],\n",
              "        [ 2045,  3632, 27937,  1012],\n",
              "        [ 2146,  9779,  2361,  1012],\n",
              "        [ 1050,  2546,  2595,  9577],\n",
              "        [ 2019,  2635,  2062,  2125],\n",
              "        [ 8292,  2078,  4911,  2041],\n",
              "        [10381,  2243,  2058,  1012],\n",
              "        [ 1049,  8117,  5210,  1012],\n",
              "        [22038,  2401,  2058,  1012],\n",
              "        [ 4562,  5210,  1029,  2013],\n",
              "        [ 4642,  2063,  2146,  2801],\n",
              "        [ 1041, 15907,  2915,  1012],\n",
              "        [20116,  2097,  2377,  2896],\n",
              "        [ 8292,  2063,  2058,  1012],\n",
              "        [ 9779,  2361,  2460,  3139],\n",
              "        [ 2794,  2000,  4903, 14227],\n",
              "        [ 7473,  2078,  2146, 16437]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT3MVzGfHZdV"
      },
      "source": [
        "Get the number of batches in the dataset.\n",
        "\n",
        "Determine number of test- & train sets (10% / 90% for this example).\n",
        "\n",
        "Shuffle the batched datasets.\n",
        "\n",
        "Create the test- and train datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPqJeYpmfcv"
      },
      "source": [
        "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)    #nr of batches\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10                      #for test data\n",
        "all_batched.shuffle(NB_BATCHES)                         #shuffle data\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)        #create test dataset using .take\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)       #create training dataset using .skip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chwmFcGDIjkQ"
      },
      "source": [
        "Extract from the test dataset the target values for later comparisons.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7POlofMdra5",
        "outputId": "ad36746f-ed9e-4fa0-f8f4-a562fbe59748"
      },
      "source": [
        "y_test = np.concatenate([element[1] for element in test_dataset.as_numpy_iterator()])\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33DXHUUthVfZ",
        "outputId": "ccf87d49-6347-49e4-b3db-1a164ed1a1b9"
      },
      "source": [
        "type(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1aQnJk-SGf5",
        "outputId": "f439c2e1-0ace-4dbe-c355-694d8a50abca"
      },
      "source": [
        "NB_BATCHES_TEST"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXir2UNazDYA",
        "outputId": "07d35239-d600-4a9f-f7d4-deab8c627dca"
      },
      "source": [
        "test_dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((32, None), (32,)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qp4NmC0zYDN",
        "outputId": "2b82a508-c8e2-4824-c689-d0eac8e98c6f"
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 4), dtype=int32, numpy=\n",
              " array([[ 5887,  2705,  2844,  2707],\n",
              "        [ 9779,  2361,  2733,  2490],\n",
              "        [ 1999, 16216,  6767,  1012],\n",
              "        [ 1050,  4292,  2039, 17950],\n",
              "        [ 9574,  2825, 25129,  2377],\n",
              "        [ 4654,  2232,  2058,  1012],\n",
              "        [10705,  2072,  2058,  1012],\n",
              "        [ 2915,  2012,  2072,  1012],\n",
              "        [10210,  2243,  3048,  2153],\n",
              "        [27937,  2023,  2003,  2009],\n",
              "        [18629,  2559,  3492,  9200],\n",
              "        [20704,  2100,  2058,  1012],\n",
              "        [ 3729,  2595,  2146,  1012],\n",
              "        [ 1049,  1996, 25129,  7172],\n",
              "        [ 9779, 10882,  5910,  2814],\n",
              "        [14925,  3835,  2275,  2039],\n",
              "        [ 2045,  3632, 27937,  1012],\n",
              "        [ 2146,  9779,  2361,  1012],\n",
              "        [ 1050,  2546,  2595,  9577],\n",
              "        [ 2019,  2635,  2062,  2125],\n",
              "        [ 8292,  2078,  4911,  2041],\n",
              "        [10381,  2243,  2058,  1012],\n",
              "        [ 1049,  8117,  5210,  1012],\n",
              "        [22038,  2401,  2058,  1012],\n",
              "        [ 4562,  5210,  1029,  2013],\n",
              "        [ 4642,  2063,  2146,  2801],\n",
              "        [ 1041, 15907,  2915,  1012],\n",
              "        [20116,  2097,  2377,  2896],\n",
              "        [ 8292,  2063,  2058,  1012],\n",
              "        [ 9779,  2361,  2460,  3139],\n",
              "        [ 2794,  2000,  4903, 14227],\n",
              "        [ 7473,  2078,  2146, 16437]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxONsFVHkFLU"
      },
      "source": [
        "# Stage 3: Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpz-eu5LmmX"
      },
      "source": [
        "Create the model with three different convolutional filter sizes of two, three and four."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6DD3k3qPLDQ"
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 emb_dim=128,       #embedding size for the vectors\n",
        "                 nb_filters=50,     #conv filters for each size 50x2, 50x3, 50x4\n",
        "                 FFN_units=512,     #hidden units used in dense layers\n",
        "                 nb_classes=2,      #nr of classes in our data - 1/0\n",
        "                 dropout_rate=0.1,  #dropout\n",
        "                 training=False,    #know if we are training/not to apply dropout/not\n",
        "                 name=\"dcnn\"):      #model name\n",
        "\n",
        "        super(DCNN, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size,\n",
        "                                          emb_dim)      #created for this model\n",
        "\n",
        "        #bigram layer focusing on 2 consecutive words\n",
        "        #1D because width of feature detector is the same as embedding dimension of vector\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters, \n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        \n",
        "        #trigram layer focusing on 3 consecutive words\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        \n",
        "        #fourgram layer focusing on 4 consecutive words\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        \n",
        "        #takes the max of each output\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "\n",
        "        #Dense layer 1\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "\n",
        "        #dropout shuts down some neurons to keep from overfitting\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        #output layer \n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "\n",
        "        x_1 = self.bigram(x)    # (batch_size, nb_filters, seq_len-1)\n",
        "        x_1 = self.pool(x_1)    # (batch_size, nb_filters)\n",
        "\n",
        "        x_2 = self.trigram(x)   # (batch_size, nb_filters, seq_len-2)\n",
        "        x_2 = self.pool(x_2)    # (batch_size, nb_filters)\n",
        "\n",
        "        x_3 = self.fourgram(x)  # (batch_size, nb_filters, seq_len-3)\n",
        "        x_3 = self.pool(x_3)    # (batch_size, nb_filters)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSix1l4jkIxp"
      },
      "source": [
        "# Stage 4: Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TUG2KROW9vG"
      },
      "source": [
        "Hyperparameters & Other Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhfUFvWEPOIf"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.5\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtdiWmwv6rD"
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
        "            emb_dim=EMB_DIM,\n",
        "            nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apbd7FrwPYo"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78cceSGCw1XC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8020613e-0e3a-42c5-9af4-dc93aba8b8f2"
      },
      "source": [
        "checkpoint_path = \"./drive/My Drive/projects/BERT/ckpt_bert_tok/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YIF5trzx7RA"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrT8oWZzQNmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b7545f-3e46-415d-cd9c-705d969651e0"
      },
      "source": [
        "Dcnn.fit(train_dataset,\n",
        "         epochs=NB_EPOCHS,\n",
        "         callbacks=[MyCustomCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "    160/Unknown - 4s 19ms/step - loss: 0.0025 - accuracy: 0.9994Checkpoint saved at ./drive/My Drive/projects/BERT/ckpt_bert_tok/.\n",
            "161/161 [==============================] - 5s 21ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Epoch 2/5\n",
            "160/161 [============================>.] - ETA: 0s - loss: 7.7161e-04 - accuracy: 0.9996Checkpoint saved at ./drive/My Drive/projects/BERT/ckpt_bert_tok/.\n",
            "161/161 [==============================] - 4s 25ms/step - loss: 7.6682e-04 - accuracy: 0.9996\n",
            "Epoch 3/5\n",
            "160/161 [============================>.] - ETA: 0s - loss: 7.5924e-04 - accuracy: 0.9994Checkpoint saved at ./drive/My Drive/projects/BERT/ckpt_bert_tok/.\n",
            "161/161 [==============================] - 4s 22ms/step - loss: 7.5453e-04 - accuracy: 0.9994\n",
            "Epoch 4/5\n",
            "161/161 [==============================] - ETA: 0s - loss: 6.4972e-04 - accuracy: 0.9994Checkpoint saved at ./drive/My Drive/projects/BERT/ckpt_bert_tok/.\n",
            "161/161 [==============================] - 4s 26ms/step - loss: 6.4972e-04 - accuracy: 0.9994\n",
            "Epoch 5/5\n",
            "160/161 [============================>.] - ETA: 0s - loss: 5.6726e-04 - accuracy: 0.9996Checkpoint saved at ./drive/My Drive/projects/BERT/ckpt_bert_tok/.\n",
            "161/161 [==============================] - 4s 21ms/step - loss: 5.6378e-04 - accuracy: 0.9996\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5e5e1d410>"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z51cjEPJ3Jdk",
        "outputId": "6456c3a4-0fbf-403f-b3cc-f0ee6344a8f9"
      },
      "source": [
        "Dcnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_23 (Embedding)    multiple                  6104400   \n",
            "                                                                 \n",
            " conv1d_69 (Conv1D)          multiple                  40100     \n",
            "                                                                 \n",
            " conv1d_70 (Conv1D)          multiple                  60100     \n",
            "                                                                 \n",
            " conv1d_71 (Conv1D)          multiple                  80100     \n",
            "                                                                 \n",
            " global_max_pooling1d_23 (Gl  multiple                 0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_46 (Dense)            multiple                  77056     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            multiple                  257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,362,013\n",
            "Trainable params: 6,362,013\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IiDW919kQQK"
      },
      "source": [
        "# Stage 5: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MthhNfnG1TPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a567af8e-2e01-4267-e639-8dfcc2c0ca6d"
      },
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 14ms/step - loss: 0.9832 - accuracy: 0.8594\n",
            "[0.9832169413566589, 0.859375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXS6CK-2RxRF",
        "outputId": "4d7a5b0d-86e9-4cf5-bb68-6fcb7c9f7990"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9780955910682678, 0.8524305820465088]"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RshSlTAKSSb0"
      },
      "source": [
        "y_pred = Dcnn.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI8F06hzlje-",
        "outputId": "8ca8179e-67c8-43bb-f475-d831f5a71efd"
      },
      "source": [
        "type(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oikZCxReq1F2"
      },
      "source": [
        "predictions = []\n",
        "for i in list(y_pred):\n",
        "    #print(i)\n",
        "    #print(math.floor(i))\n",
        "    #print(math.floor(i*2))\n",
        "    if i <1.0:\n",
        "        predictions.append(math.floor(i*2))\n",
        "    else:\n",
        "        predictions.append(math.floor(i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48DuKXk2oBps",
        "outputId": "2d6d5c96-5f28-46c7-9206-7286e84bc2bc"
      },
      "source": [
        "type(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbcl3CSyT8sW",
        "outputId": "b0d6f47a-1274-4dac-9581-1997d372d7b3"
      },
      "source": [
        "cm = confusion_matrix(y_test, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[143  37]\n",
            " [ 44 352]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOYeiiV7e_3Z",
        "outputId": "a890d61d-41d6-4dbf-dca3-b0acd27e2eed"
      },
      "source": [
        "acc = accuracy_score(y_test, predictions)\n",
        "auc = roc_auc_score(y_test, predictions, multi_class=\"ovr\")\n",
        "print(\"Accuracy:\",  round(acc,2))\n",
        "print(\"Auc:\", round(auc,2))\n",
        "print(\"Detail:\")\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86\n",
            "Auc: 0.84\n",
            "Detail:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.79      0.78       180\n",
            "           1       0.90      0.89      0.90       396\n",
            "\n",
            "    accuracy                           0.86       576\n",
            "   macro avg       0.83      0.84      0.84       576\n",
            "weighted avg       0.86      0.86      0.86       576\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpDRaRJ8Rsxg"
      },
      "source": [
        "# Stage 6: Predictions for individual tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section create a function to make predictions with and feed some recent tweets into the model to evaluate how well the model interprets recent tweets.  \n",
        "\n",
        "Understanding incorrect predictions are just as important as understanding correct predictions.  Obtaining more data to test predictions will be a next phase in understanding and interpreting the model's behaviour.  "
      ],
      "metadata": {
        "id": "VVmeIbD0IoRm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jrRvtl1xuk"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "    tokens = encode_sentence(sentence)\n",
        "    inputs = tf.expand_dims(tokens, 0)   #simulate a batch (of 1)\n",
        "\n",
        "    output = Dcnn(inputs, training=False)\n",
        "\n",
        "    sentiment = math.floor(output*2)\n",
        "\n",
        "    if sentiment == 0:\n",
        "        print(\"Ouput of the model: {}\\nPredicted sentiment: negative.\".format(\n",
        "            output))\n",
        "    elif sentiment == 1:\n",
        "        print(\"Ouput of the model: {}\\nPredicted sentiment: positive.\".format(\n",
        "            output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correct predictions "
      ],
      "metadata": {
        "id": "0qayQVA-Lfkn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6F1i68LK-xe",
        "outputId": "c8c4c514-9afc-42c3-f9db-40ed6c962991"
      },
      "source": [
        "get_prediction(\"The market size and demographics, as we wrote about here, leading into the IPO, are attractive.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouput of the model: [[0.9898499]]\n",
            "Predicted sentiment: positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec9ITV4aLKbq",
        "outputId": "047fa988-9bda-41e1-b415-c8f74c426283"
      },
      "source": [
        "get_prediction(\"DraftKings would still be losing $200 million a quarter,” Chanos said. “That is completely and totally insane.” He said has been short the stock for most of this year.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouput of the model: [[2.3337441e-05]]\n",
            "Predicted sentiment: negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXiX7A9rLP4Y",
        "outputId": "fbc2494f-a084-4a7f-c37e-f7d9d8a1c6e2"
      },
      "source": [
        "get_prediction(\"Just a reminder that our debt bomb not going away. A year ago it was R2,9 trillion. At some stage this becomes a major problem...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouput of the model: [[0.01473029]]\n",
            "Predicted sentiment: negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHK0Jq4wns6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7713d207-af55-45cd-810a-f1a18f73e819"
      },
      "source": [
        "get_prediction(\"Now track SA under the ANC and understand why R300bn has left the JSE bond and equity market this year.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouput of the model: [[0.1265002]]\n",
            "Predicted sentiment: negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Incorrect predictions"
      ],
      "metadata": {
        "id": "tTKhvzV9L2ZZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMyVjgSt3Nze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877c59cb-0ac6-4202-a60a-d1de2161cb04"
      },
      "source": [
        "get_prediction(\"I see Karoooo up 6.3% this morning. A closer look shows stock up on trades of 72 shares worth all of R41200. Serious. The gain though moves the market cap up R1bn. The fun you can have in illiquid markets!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouput of the model: [[0.20105565]]\n",
            "Predicted sentiment: negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty5VZcDnnzEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b5937e-8e2c-4038-f474-520e03808310"
      },
      "source": [
        "get_prediction(\"International investors in SA rail sector threaten to disinvest\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouput of the model: [[0.9941408]]\n",
            "Predicted sentiment: positive.\n"
          ]
        }
      ]
    }
  ]
}